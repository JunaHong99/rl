# import torch
# import numpy as np
# import os
# import argparse
# from datetime import datetime
# import isaaclab.utils.math as math_utils

# # Isaac Lab Imports
# from isaaclab.app import AppLauncher

# # argparse ì„¤ì •
# parser = argparse.ArgumentParser(description="Test Agent on Fixed Dataset")
# parser.add_argument("--model_path", type=str, required=True, help="Path to the checkpoint (e.g., logs/.../model_step_50000)")
# parser.add_argument("--num_envs", type=int, default=100, help="Fixed to 100 for consistent testing")
# parser.add_argument("--dataset_file", type=str, default="test_dataset_100.pt", help="File to save/load fixed test episodes")

# AppLauncher.add_app_launcher_args(parser)
# args_cli = parser.parse_args()

# # App ì‹¤í–‰
# app_launcher = AppLauncher(args_cli)
# simulation_app = app_launcher.app

# # ë‚˜ë¨¸ì§€ ì„í¬íŠ¸
# from dual_arm_transport_env3 import DualrobotEnv, DualrobotCfg
# from graph_converter import convert_batch_state_to_graph, NODE_FEATURE_DIM, EDGE_FEATURE_DIM, GLOBAL_FEATURE_DIM
# from agent import TD3
# from vectorized_pose_sampler import VectorizedPoseSampler

# def generate_and_save_dataset(filepath, num_samples, device="cpu"):
#     """
#     í…ŒìŠ¤íŠ¸ìš© ì´ˆê¸° ìƒíƒœë¥¼ ë²¡í„°í™”ëœ ìƒ˜í”ŒëŸ¬ë¥¼ í†µí•´ ìƒì„±í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     print(f"Generating new test dataset with {num_samples} samples using VectorizedPoseSampler...")
#     sampler = VectorizedPoseSampler(device=device)
    
#     # ë²¡í„°í™”ëœ ìƒ˜í”Œë§ ì‹¤í–‰
#     samples = sampler.sample_episodes(num_samples)
    
#     data = {
#         "base_pose_1": samples["base_pose_1"],
#         "base_pose_2": samples["base_pose_2"],
#         "q_start_1": samples["q_start_1"],
#         "q_start_2": samples["q_start_2"],
#         "goal_ee1": samples["goal_ee1_pose"],
#         "goal_ee2": samples["goal_ee2_pose"]
#     }
        
#     torch.save(data, filepath)
#     print(f"Saved dataset to {filepath}")
#     return data

# def main():
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
#     # 1. Dataset ì¤€ë¹„
#     if os.path.exists(args_cli.dataset_file):
#         print(f"Loading existing dataset: {args_cli.dataset_file}")
#         dataset = torch.load(args_cli.dataset_file, map_location=device)
        
#         # [Validation] Check size compatibility
#         loaded_size = dataset["base_pose_1"].shape[0]
#         if loaded_size != args_cli.num_envs:
#             print(f"âš ï¸ Dataset size mismatch! Loaded: {loaded_size}, Requested: {args_cli.num_envs}")
            
#             if loaded_size > args_cli.num_envs:
#                 print(f"ğŸ“‰ Slicing dataset to match {args_cli.num_envs}...")
#                 for k in dataset:
#                     dataset[k] = dataset[k][:args_cli.num_envs]
#             else:
#                 print(f"ğŸ“ˆ Requested more envs than dataset has. Regenerating {args_cli.num_envs} samples...")
#                 dataset = generate_and_save_dataset(args_cli.dataset_file, args_cli.num_envs, device=device)
#     else:
#         dataset = generate_and_save_dataset(args_cli.dataset_file, args_cli.num_envs, device=device)

#     # 2. í™˜ê²½ ì„¤ì •
#     env_cfg = DualrobotCfg()
#     env_cfg.scene.num_envs = args_cli.num_envs
#     env = DualrobotEnv(cfg=env_cfg, render_mode=None) # ì†ë„ë¥¼ ìœ„í•´ ë Œë”ë§ ë”

#     # 3. ì—ì´ì „íŠ¸ ë¡œë“œ
#     gnn_params = {
#         'node_dim': NODE_FEATURE_DIM,
#         'edge_dim': EDGE_FEATURE_DIM,
#         'global_dim': GLOBAL_FEATURE_DIM,
#         'action_dim': 7
#     }
#     agent = TD3(gnn_params=gnn_params, max_action=1.0)
    
#     # ëª¨ë¸ ë¡œë“œ (actorë§Œ ìˆì–´ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ì§€ë§Œ êµ¬ì¡°ìƒ load í•¨ìˆ˜ ì‚¬ìš©)
#     # resume_pathê°€ full pathë¼ê³  ê°€ì •
#     print(f"Loading model from {args_cli.model_path}...")
#     try:
#         # [ìˆ˜ì •] Actorë§Œ ì§ì ‘ ë¡œë“œ (Actor íŒŒì¼ ê²½ë¡œê°€ ì§ì ‘ ì£¼ì–´ì¡Œì„ ê²½ìš° ëŒ€ì‘)
#         agent.actor.load_state_dict(torch.load(args_cli.model_path, map_location=device))
#         print("âœ… Actor model loaded successfully.")
#     except Exception as e:
#         print(f"âš ï¸ Failed to load actor directly: {e}")
#         print("Attempting agent.load() fallback...")
#         try:
#             agent.load(args_cli.model_path)
#         except Exception as e2:
#             print(f"âŒ Error loading model: {e2}")
#             return

#     # 4. í…ŒìŠ¤íŠ¸ ë£¨í”„
#     print(f"Starting evaluation on {args_cli.num_envs} fixed episodes...")
    
#     # [Optimized] Inject dataset directly into env to skip expensive IK sampling in reset()
#     # Key mapping: dataset uses 'goal_ee1', env expects 'goal_ee1_pose'
#     external_samples = {
#         "base_pose_1": dataset["base_pose_1"],
#         "base_pose_2": dataset["base_pose_2"],
#         "q_start_1": dataset["q_start_1"],
#         "q_start_2": dataset["q_start_2"],
#         "goal_ee1_pose": dataset["goal_ee1"],
#         "goal_ee2_pose": dataset["goal_ee2"]
#     }
#     env.external_samples = external_samples

#     # Now reset() uses the external_samples efficiently
#     obs_dict, _ = env.reset()
    
#     # force_apply_dataset is no longer needed as reset() applied the external_samples
    
#     # ë¬¼ë¦¬ ì—”ì§„ì— ì ìš©ëœ ìƒíƒœë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ê´€ì¸¡ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°
#     obs_dict = env._get_observations() 
    
#     current_batch_graph = convert_batch_state_to_graph(obs_dict['policy'], args_cli.num_envs)

#     # í†µê³„ ë³€ìˆ˜ (Latches & Masks)
#     total_rewards = torch.zeros(env.num_envs, device=device)
#     any_success = torch.zeros(env.num_envs, dtype=torch.bool, device=device)
#     any_violation = torch.zeros(env.num_envs, dtype=torch.bool, device=device)
#     any_reached = torch.zeros(env.num_envs, dtype=torch.bool, device=device)
#     active_mask = torch.ones(env.num_envs, dtype=torch.bool, device=device) # ì²« ì—í”¼ì†Œë“œ ì§„í–‰ ì¤‘ì´ë©´ True
    
#     # ì—í”¼ì†Œë“œ ê¸¸ì´ë§Œí¼ ì‹¤í–‰ (í™˜ê²½ì˜ max_length ì‚¬ìš©)
#     max_steps = 100 # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ í•˜ë“œì½”ë”© í˜¹ì€ env.max_episode_length
    
#     agent.actor.eval()
    
#     print(f"Running simulation for {max_steps} steps...")
    
#     for step in range(max_steps):
#         # Action Inference (No Grad for Policy)
#         with torch.no_grad():
#             full_actions = agent.actor(current_batch_graph)
            
#             # Reshape & Slice (Trainê³¼ ë™ì¼ ë¡œì§)
#             total_nodes = full_actions.shape[0]
#             num_nodes_per_env = total_nodes // args_cli.num_envs
#             reshaped_actions = full_actions.view(args_cli.num_envs, num_nodes_per_env, -1)
#             robot_actions = reshaped_actions[:, :2, :] 
#             env_actions = robot_actions.reshape(args_cli.num_envs, -1)
        
#         # Step (Grad Enabled for Internal IK/Sim Ops)
#         next_obs_dict, rewards, terminated, truncated, extras = env.step(env_actions)
        
#         if (step + 1) % 10 == 0:
#             print(f"Step {step+1}/{max_steps} completed.")
        
#         dones = terminated | truncated
        
#         # 1. Rewards Accumulation (í™œì„± ìƒíƒœì¸ í™˜ê²½ë§Œ)
#         total_rewards += rewards * active_mask.float()
        
#         # 2. Success Latch
#         if "log/success" in extras:
#             current_success = (extras["log/success"] > 0.5)
#             any_success = torch.logical_or(any_success, current_success & active_mask)

#         # 3. Violation Latch
#         if "log/violation" in extras:
#             current_violation = (extras["log/violation"] > 0.5)
#             any_violation = torch.logical_or(any_violation, current_violation & active_mask)

#         # [NEW] 4. Reached Latch
#         if "log/is_reached" in extras:
#             current_reached = (extras["log/is_reached"] > 0.5)
#             any_reached = torch.logical_or(any_reached, current_reached & active_mask)
        
#         # 5. Mask Update (ëë‚œ í™˜ê²½ì€ ë¹„í™œì„±í™”)
#         active_mask = active_mask & (~dones)
        
#         # ëª¨ë“  í™˜ê²½ì´ ëë‚¬ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
#         if not active_mask.any():
#             print(f"All episodes finished at step {step+1}.")
#             break
        
#         current_batch_graph = convert_batch_state_to_graph(next_obs_dict['policy'], args_cli.num_envs)

#     # 5. ê²°ê³¼ ì§‘ê³„
#     print("\n" + "="*50)
#     print(f"Evaluation Results ({args_cli.num_envs} Episodes)")
#     print("="*50)
#     print(f"Success Rate        : {torch.mean(any_success.float()).item()*100:.2f}%")
#     print(f"Violation Rate      : {torch.mean(any_violation.float()).item()*100:.2f}%")
#     print(f"Reached Rate        : {torch.mean(any_reached.float()).item()*100:.2f}%")
#     print(f"Avg Total Reward    : {torch.mean(total_rewards).item():.4f}")
#     print("="*50)

#     # ê²°ê³¼ íŒŒì¼ ì €ì¥ (ì„ íƒ)
#     # with open("test_results.txt", "a") as f:
#     #     f.write(f"{args_cli.model_path}, {torch.mean(final_success).item()}\n")

#     env.close()
#     simulation_app.close()

# if __name__ == "__main__":
#     main()

import torch
import numpy as np
import os
import argparse
from datetime import datetime
import isaaclab.utils.math as math_utils

# Isaac Lab Imports
from isaaclab.app import AppLauncher

# argparse ì„¤ì •
parser = argparse.ArgumentParser(description="Test Agent on Fixed Dataset")
parser.add_argument("--model_path", type=str, required=True, help="Path to the checkpoint (e.g., logs/.../model_step_50000)")
parser.add_argument("--num_envs", type=int, default=100, help="Fixed to 100 for consistent testing")
parser.add_argument("--dataset_file", type=str, default="test_dataset_100.pt", help="File to save/load fixed test episodes")
parser.add_argument("--save_failures", action="store_true", help="Save failed episodes (not reached or violated) to failed_episodes.pt")

AppLauncher.add_app_launcher_args(parser)
args_cli = parser.parse_args()

# App ì‹¤í–‰
app_launcher = AppLauncher(args_cli)
simulation_app = app_launcher.app

# ë‚˜ë¨¸ì§€ ì„í¬íŠ¸
from dual_arm_transport_env3 import DualrobotEnv, DualrobotCfg
from graph_converter import convert_batch_state_to_graph, NODE_FEATURE_DIM, EDGE_FEATURE_DIM, GLOBAL_FEATURE_DIM
from agent import TD3
from vectorized_pose_sampler import VectorizedPoseSampler

def generate_and_save_dataset(filepath, num_samples, device="cpu"):
    """
    í…ŒìŠ¤íŠ¸ìš© ì´ˆê¸° ìƒíƒœë¥¼ ë²¡í„°í™”ëœ ìƒ˜í”ŒëŸ¬ë¥¼ í†µí•´ ìƒì„±í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    print(f"Generating new test dataset with {num_samples} samples using VectorizedPoseSampler...")
    sampler = VectorizedPoseSampler(device=device)
    
    # ë²¡í„°í™”ëœ ìƒ˜í”Œë§ ì‹¤í–‰
    samples = sampler.sample_episodes(num_samples)
    
    data = {
        "base_pose_1": samples["base_pose_1"],
        "base_pose_2": samples["base_pose_2"],
        "q_start_1": samples["q_start_1"],
        "q_start_2": samples["q_start_2"],
        "goal_ee1": samples["goal_ee1_pose"],
        "goal_ee2": samples["goal_ee2_pose"]
    }
        
    torch.save(data, filepath)
    print(f"Saved dataset to {filepath}")
    return data

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 1. Dataset ì¤€ë¹„
    if os.path.exists(args_cli.dataset_file):
        print(f"Loading existing dataset: {args_cli.dataset_file}")
        dataset = torch.load(args_cli.dataset_file, map_location=device)
        
        # [Validation] Check size compatibility
        loaded_size = dataset["base_pose_1"].shape[0]
        if loaded_size != args_cli.num_envs:
            print(f"âš ï¸ Dataset size mismatch! Loaded: {loaded_size}, Requested: {args_cli.num_envs}")
            
            if loaded_size > args_cli.num_envs:
                print(f"ğŸ“‰ Slicing dataset to match {args_cli.num_envs}...")
                for k in dataset:
                    dataset[k] = dataset[k][:args_cli.num_envs]
            else:
                print(f"ğŸ“ˆ Requested more envs than dataset has. Regenerating {args_cli.num_envs} samples...")
                dataset = generate_and_save_dataset(args_cli.dataset_file, args_cli.num_envs, device=device)
    else:
        dataset = generate_and_save_dataset(args_cli.dataset_file, args_cli.num_envs, device=device)

    # 2. í™˜ê²½ ì„¤ì •
    env_cfg = DualrobotCfg()
    env_cfg.scene.num_envs = args_cli.num_envs
    env = DualrobotEnv(cfg=env_cfg, render_mode=None) # ì†ë„ë¥¼ ìœ„í•´ ë Œë”ë§ ë”

    # 3. ì—ì´ì „íŠ¸ ë¡œë“œ
    gnn_params = {
        'node_dim': NODE_FEATURE_DIM,
        'edge_dim': EDGE_FEATURE_DIM,
        'global_dim': GLOBAL_FEATURE_DIM,
        'action_dim': 7
    }
    agent = TD3(gnn_params=gnn_params, max_action=1.0)
    
    # ëª¨ë¸ ë¡œë“œ (actorë§Œ ìˆì–´ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ì§€ë§Œ êµ¬ì¡°ìƒ load í•¨ìˆ˜ ì‚¬ìš©)
    # resume_pathê°€ full pathë¼ê³  ê°€ì •
    print(f"Loading model from {args_cli.model_path}...")
    try:
        # [ìˆ˜ì •] Actorë§Œ ì§ì ‘ ë¡œë“œ (Actor íŒŒì¼ ê²½ë¡œê°€ ì§ì ‘ ì£¼ì–´ì¡Œì„ ê²½ìš° ëŒ€ì‘)
        agent.actor.load_state_dict(torch.load(args_cli.model_path, map_location=device))
        print("âœ… Actor model loaded successfully.")
    except Exception as e:
        print(f"âš ï¸ Failed to load actor directly: {e}")
        print("Attempting agent.load() fallback...")
        try:
            agent.load(args_cli.model_path)
        except Exception as e2:
            print(f"âŒ Error loading model: {e2}")
            return

    # 4. í…ŒìŠ¤íŠ¸ ë£¨í”„
    print(f"Starting evaluation on {args_cli.num_envs} fixed episodes...")
    
    # [Optimized] Inject dataset directly into env to skip expensive IK sampling in reset()
    # Key mapping: dataset uses 'goal_ee1', env expects 'goal_ee1_pose'
    external_samples = {
        "base_pose_1": dataset["base_pose_1"],
        "base_pose_2": dataset["base_pose_2"],
        "q_start_1": dataset["q_start_1"],
        "q_start_2": dataset["q_start_2"],
        "goal_ee1_pose": dataset["goal_ee1"],
        "goal_ee2_pose": dataset["goal_ee2"]
    }
    env.external_samples = external_samples

    # Now reset() uses the external_samples efficiently
    obs_dict, _ = env.reset()
    
    # force_apply_dataset is no longer needed as reset() applied the external_samples
    
    # ë¬¼ë¦¬ ì—”ì§„ì— ì ìš©ëœ ìƒíƒœë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ê´€ì¸¡ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°
    obs_dict = env._get_observations() 
    
    current_batch_graph = convert_batch_state_to_graph(obs_dict['policy'], args_cli.num_envs)

    # í†µê³„ ë³€ìˆ˜ (Latches & Masks)
    total_rewards = torch.zeros(env.num_envs, device=device)
    any_success = torch.zeros(env.num_envs, dtype=torch.bool, device=device)
    any_violation = torch.zeros(env.num_envs, dtype=torch.bool, device=device)
    any_reached = torch.zeros(env.num_envs, dtype=torch.bool, device=device)
    active_mask = torch.ones(env.num_envs, dtype=torch.bool, device=device) # ì²« ì—í”¼ì†Œë“œ ì§„í–‰ ì¤‘ì´ë©´ True
    
    # ì—í”¼ì†Œë“œ ê¸¸ì´ë§Œí¼ ì‹¤í–‰ (í™˜ê²½ì˜ max_length ì‚¬ìš©)
    max_steps = 200 # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ í•˜ë“œì½”ë”© í˜¹ì€ env.max_episode_length
    
    agent.actor.eval()
    
    print(f"Running simulation for {max_steps} steps...")
    
    for step in range(max_steps):
        # Action Inference (No Grad for Policy)
        with torch.no_grad():
            full_actions = agent.actor(current_batch_graph)
            
            # Reshape & Slice (Trainê³¼ ë™ì¼ ë¡œì§)
            total_nodes = full_actions.shape[0]
            num_nodes_per_env = total_nodes // args_cli.num_envs
            reshaped_actions = full_actions.view(args_cli.num_envs, num_nodes_per_env, -1)
            robot_actions = reshaped_actions[:, :2, :] 
            env_actions = robot_actions.reshape(args_cli.num_envs, -1)
        
        # Step (Grad Enabled for Internal IK/Sim Ops)
        next_obs_dict, rewards, terminated, truncated, extras = env.step(env_actions)
        
        if (step + 1) % 10 == 0:
            print(f"Step {step+1}/{max_steps} completed.")
        
        dones = terminated | truncated
        
        # 1. Rewards Accumulation (í™œì„± ìƒíƒœì¸ í™˜ê²½ë§Œ)
        total_rewards += rewards * active_mask.float()
        
        # 2. Success Latch
        if "log/success" in extras:
            current_success = (extras["log/success"] > 0.5)
            any_success = torch.logical_or(any_success, current_success & active_mask)

        # 3. Violation Latch
        if "log/violation" in extras:
            current_violation = (extras["log/violation"] > 0.5)
            any_violation = torch.logical_or(any_violation, current_violation & active_mask)

        # [NEW] 4. Reached Latch
        if "log/is_reached" in extras:
            current_reached = (extras["log/is_reached"] > 0.5)
            any_reached = torch.logical_or(any_reached, current_reached & active_mask)
        
        # 5. Mask Update (ëë‚œ í™˜ê²½ì€ ë¹„í™œì„±í™”)
        active_mask = active_mask & (~dones)
        
        # ëª¨ë“  í™˜ê²½ì´ ëë‚¬ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
        if not active_mask.any():
            print(f"All episodes finished at step {step+1}.")
            break
        
        current_batch_graph = convert_batch_state_to_graph(next_obs_dict['policy'], args_cli.num_envs)

    # 5. ê²°ê³¼ ì§‘ê³„
    # Calculate detailed metrics
    reached_but_violated = torch.logical_and(any_reached, any_violation)
    not_reached = ~any_reached
    
    success_rate = torch.mean(any_success.float()).item() * 100
    violation_rate = torch.mean(any_violation.float()).item() * 100
    reached_rate = torch.mean(any_reached.float()).item() * 100
    
    reached_but_violated_rate = torch.mean(reached_but_violated.float()).item() * 100
    not_reached_rate = torch.mean(not_reached.float()).item() * 100
    
    # Conditional Violation Rate (Violation given Reached)
    num_reached = torch.sum(any_reached.float()).item()
    if num_reached > 0:
        cond_violation_rate = (torch.sum(reached_but_violated.float()).item() / num_reached) * 100
    else:
        cond_violation_rate = 0.0

    print("\n" + "="*50)
    print(f"Evaluation Results ({args_cli.num_envs} Episodes)")
    print("="*50)
    print(f"Success Rate            : {success_rate:.2f}%")
    print(f"Reached Rate (Total)    : {reached_rate:.2f}%")
    print(f"Violation Rate (Total)  : {violation_rate:.2f}%")
    print("-" * 30)
    print("Failure Analysis:")
    print(f"  - Not Reached         : {not_reached_rate:.2f}% (Failed to approach goal)")
    print(f"  - Reached but Violated: {reached_but_violated_rate:.2f}% (Reached goal but failed constraint)")
    print(f"  - Cond. Violation Rate: {cond_violation_rate:.2f}% (Violation / Reached)")
    print("-" * 30)
    print(f"Avg Total Reward        : {torch.mean(total_rewards).item():.4f}")
    print("="*50)

    # Save failed episodes if requested
    if args_cli.save_failures:
        # Failure definition: Not Reached OR Violation
        # reached_but_violated is subset of any_violation, so we just check any_violation for simplicity if that's the intent.
        # However, user mentioned "Not Reached" specifically. Let's capture ANY failure (Success=False).
        # failed_mask = ~any_success # Captures both Not Reached and Violations
        
        # Or specifically as discussed: Not Reached AND Reached-But-Violated
        failed_mask = torch.logical_or(not_reached, any_violation)
        
        failed_indices = torch.nonzero(failed_mask).flatten()
        num_failed = failed_indices.numel()
        
        if num_failed > 0:
            print(f"\n[Save Failures] Found {num_failed} failed episodes.")
            failed_data = {}
            # env.external_samples has the raw data used for reset
            src = env.external_samples
            
            for key in src:
                # Select only failed indices
                failed_data[key] = src[key][failed_indices]
            
            # Add metadata about failure type
            failed_data["failure_reason"] = []
            for idx in failed_indices:
                if not_reached[idx]:
                    failed_data["failure_reason"].append("not_reached")
                elif reached_but_violated[idx]:
                    failed_data["failure_reason"].append("reached_but_violated")
                else:
                    failed_data["failure_reason"].append("unknown_failure") # Should not happen with current logic

            save_path = "failed_episodes.pt"
            torch.save(failed_data, save_path)
            print(f"âŒ Saved failed episodes to {save_path}")
        else:
            print("\n[Save Failures] No failures detected! Nothing to save.")

    # ê²°ê³¼ íŒŒì¼ ì €ì¥ (ì„ íƒ)
    # with open("test_results.txt", "a") as f:
    #     f.write(f"{args_cli.model_path}, {torch.mean(final_success).item()}\n")

    env.close()
    simulation_app.close()

if __name__ == "__main__":
    main()